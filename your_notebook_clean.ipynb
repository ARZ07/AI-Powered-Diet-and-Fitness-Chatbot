{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b6agj0gIRtY",
    "outputId": "e4a0bc70-d852-4469-b8c5-a8951ccbdbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.27.0)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.185.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers google-generativeai datasets pandas torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IFiUEDDIX6z",
    "outputId": "1d657be3-fa45-4c17-c768-0d4b61da7d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
      "-rw-r--r-- 1 root root 68 Oct 30 08:00 /root/.kaggle/kaggle.json\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "ref                                                            title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "-------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
      "ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset   Global Earthquake-Tsunami Risk Assessment Dataset       16151  2025-10-01 16:35:53.273000          15772        536  1.0              \n",
      "jockeroika/life-style-data                                     Life Style Data                                       3995645  2025-10-14 13:50:45.303000          18521        375  0.8235294        \n",
      "jaderz/hospital-beds-management                                Hospital Beds Management                                47583  2025-10-03 09:21:58.590000          12846        323  1.0              \n",
      "ayeshaimran123/social-media-and-mental-health-balance          Social Media and Mental Health Balance                   5941  2025-10-26 07:51:53.380000            799         28  1.0              \n",
      "ahmadrazakashif/bmw-worldwide-sales-records-20102024           BMW Worldwide Sales Records (2010\u20132024)                853348  2025-09-20 14:39:45.280000          16783        332  1.0              \n",
      "grandmaster07/student-exam-score-dataset-analysis              Student exam score dataset analysis                      2430  2025-09-26 07:44:12.677000           9062        203  1.0              \n",
      "ahmadrazakashif/netflix-streaming-data                         Netflix_Streaming_Data                                1400865  2025-10-09 17:53:56.590000           1607         32  1.0              \n",
      "mubeenshehzadi/customer-purchase-behaviour                     Customer Purchase Behaviour                             72157  2025-10-18 01:46:11.677000           1510         35  1.0              \n",
      "marixe/zara-sales-for-eda                                      Zara Sales for EDA \ud83d\udecd\ufe0f                                  954444  2025-10-26 12:40:24.927000           1032         21  1.0              \n",
      "alamshihab075/mental-health-dataset                            Mental Health Dataset                                 1109509  2025-10-23 11:29:29.797000           1144         33  1.0              \n",
      "tan5577/heart-failure-dataset                                  Heart_Failure_Dataset                                    8762  2025-10-19 16:54:19.303000           1353         35  1.0              \n",
      "prince7489/mental-health-and-social-media-balance-dataset      Mental Health & Social Media Balance Dataset             5941  2025-10-15 15:56:35.387000           2433         62  0.9411765        \n",
      "ahmadrazakashif/shopping-behavior-dataset                      Shopping_Behavior_Dataset                               72157  2025-10-08 16:19:06.293000           2661         41  1.0              \n",
      "mohamedasak/imdb-top-250-movies                                IMDb Top 250 Movies                                     35115  2025-10-29 23:22:58.290000            992         23  1.0              \n",
      "mohankrishnathalla/medical-insurance-cost-prediction           Medical Insurance Cost Prediction                     5897923  2025-10-10 15:35:01.663000           3006         68  1.0              \n",
      "ayeshaimran123/data-science-student-marks                      Data Science Student Marks                               5199  2025-10-09 08:22:41.593000           1493         54  1.0              \n",
      "anassarfraz13/student-success-factors-and-insights             Student Success: Factors & Insights                     96178  2025-09-24 07:58:55.117000           6276        105  1.0              \n",
      "ayeshaimran123/bmw-car-data-analysis                           BMW Car Data Analysis                                  112601  2025-10-17 05:34:49.407000           1226         35  1.0              \n",
      "asadullahcreative/global-gdp-explorer-2024-world-bank-un-data  \ud83d\udcb0 Global GDP Dataset (Latest)                            6672  2025-10-17 17:58:50.040000            844         27  1.0              \n",
      "mohankrishnathalla/mobile-reviews-sentiment-and-specification  Global Mobile Reviews Dataset (2025 Edition)          2211906  2025-10-22 16:01:13.550000           1252         29  1.0              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directly input your Kaggle API key and username\n",
    "kaggle_api_key = \"api-key\"\n",
    "kaggle_username = \"username\"\n",
    "\n",
    "# Set the environment variable for Kaggle API key\n",
    "os.environ['KAGGLE_JSON'] = kaggle_api_key\n",
    "\n",
    "# Install the Kaggle package\n",
    "!pip install kaggle\n",
    "\n",
    "# Create the directory for the Kaggle config if it doesn't exist\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "\n",
    "# Save the API key as a JSON file for authentication\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    f.write('{\"username\":\"' + kaggle_username + '\",\"key\":\"' + kaggle_api_key + '\"}')\n",
    "\n",
    "# Verify if the file is created\n",
    "!ls -alh /root/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLVp7dMsIeBZ",
    "outputId": "0b7ce590-3b50-4dd5-f231-7a9a71c94a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/valakhorasani/gym-members-exercise-dataset\n",
      "License(s): apache-2.0\n",
      "Downloading gym-members-exercise-dataset.zip to /content\n",
      "  0% 0.00/21.6k [00:00<?, ?B/s]\n",
      "100% 21.6k/21.6k [00:00<00:00, 57.8MB/s]\n",
      "Archive:  gym-members-exercise-dataset.zip\n",
      "  inflating: gym_members_exercise_tracking.csv  \n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/trolukovich/nutritional-values-for-common-foods-and-products\n",
      "License(s): CC0-1.0\n",
      "Downloading nutritional-values-for-common-foods-and-products.zip to /content\n",
      "  0% 0.00/1.27M [00:00<?, ?B/s]\n",
      "100% 1.27M/1.27M [00:00<00:00, 572MB/s]\n",
      "Archive:  nutritional-values-for-common-foods-and-products.zip\n",
      "  inflating: nutrition.csv           \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d valakhorasani/gym-members-exercise-dataset\n",
    "!unzip gym-members-exercise-dataset\n",
    "!kaggle datasets download -d trolukovich/nutritional-values-for-common-foods-and-products\n",
    "!unzip nutritional-values-for-common-foods-and-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2HITTDsIhEA",
    "outputId": "588b6397-1cb3-404a-8f92-51a63ba54b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             name serving_size  calories total_fat saturated_fat  \\\n",
      "0           0       Cornstarch        100 g       381      0.1g           NaN   \n",
      "1           1     Nuts, pecans        100 g       691       72g          6.2g   \n",
      "2           2    Eggplant, raw        100 g        25      0.2g           NaN   \n",
      "3           3   Teff, uncooked        100 g       367      2.4g          0.4g   \n",
      "4           4  Sherbet, orange        100 g       144        2g          1.2g   \n",
      "\n",
      "  cholesterol    sodium  choline     folate  ...      fat  \\\n",
      "0           0   9.00 mg   0.4 mg   0.00 mcg  ...   0.05 g   \n",
      "1           0   0.00 mg  40.5 mg  22.00 mcg  ...  71.97 g   \n",
      "2           0   2.00 mg   6.9 mg  22.00 mcg  ...   0.18 g   \n",
      "3           0  12.00 mg  13.1 mg          0  ...   2.38 g   \n",
      "4         1mg  46.00 mg   7.7 mg   4.00 mcg  ...   2.00 g   \n",
      "\n",
      "  saturated_fatty_acids monounsaturated_fatty_acids  \\\n",
      "0               0.009 g                     0.016 g   \n",
      "1               6.180 g                    40.801 g   \n",
      "2               0.034 g                     0.016 g   \n",
      "3               0.449 g                     0.589 g   \n",
      "4               1.160 g                     0.530 g   \n",
      "\n",
      "  polyunsaturated_fatty_acids fatty_acids_total_trans alcohol     ash  \\\n",
      "0                     0.025 g                 0.00 mg   0.0 g  0.09 g   \n",
      "1                    21.614 g                 0.00 mg   0.0 g  1.49 g   \n",
      "2                     0.076 g                 0.00 mg   0.0 g  0.66 g   \n",
      "3                     1.071 g                       0       0  2.37 g   \n",
      "4                     0.080 g                 1.00 mg   0.0 g  0.40 g   \n",
      "\n",
      "  caffeine theobromine    water  \n",
      "0  0.00 mg     0.00 mg   8.32 g  \n",
      "1  0.00 mg     0.00 mg   3.52 g  \n",
      "2  0.00 mg     0.00 mg  92.30 g  \n",
      "3        0           0   8.82 g  \n",
      "4  0.00 mg     0.00 mg  66.10 g  \n",
      "\n",
      "[5 rows x 77 columns]\n",
      "   Age  Gender  Weight (kg)  Height (m)  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
      "0   56    Male         88.3        1.71      180      157           60   \n",
      "1   46  Female         74.9        1.53      179      151           66   \n",
      "2   32  Female         68.1        1.66      167      122           54   \n",
      "3   25    Male         53.2        1.70      190      164           56   \n",
      "4   38    Male         46.1        1.79      188      158           68   \n",
      "\n",
      "   Session_Duration (hours)  Calories_Burned Workout_Type  Fat_Percentage  \\\n",
      "0                      1.69           1313.0         Yoga            12.6   \n",
      "1                      1.30            883.0         HIIT            33.9   \n",
      "2                      1.11            677.0       Cardio            33.4   \n",
      "3                      0.59            532.0     Strength            28.8   \n",
      "4                      0.64            556.0     Strength            29.2   \n",
      "\n",
      "   Water_Intake (liters)  Workout_Frequency (days/week)  Experience_Level  \\\n",
      "0                    3.5                              4                 3   \n",
      "1                    2.1                              4                 2   \n",
      "2                    2.3                              4                 2   \n",
      "3                    2.1                              3                 1   \n",
      "4                    2.8                              3                 1   \n",
      "\n",
      "     BMI  \n",
      "0  30.20  \n",
      "1  32.00  \n",
      "2  24.71  \n",
      "3  18.41  \n",
      "4  14.39  \n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face using your API key\n",
    "login(token=\"api key\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the nutritional values dataset\n",
    "nutrition_data = pd.read_csv(\"nutrition.csv\")\n",
    "\n",
    "# Load the gym exercises dataset\n",
    "gym_exercises_data = pd.read_csv(\"gym_members_exercise_tracking.csv\")\n",
    "\n",
    "# Check the first few rows of both datasets\n",
    "print(nutrition_data.head())\n",
    "print(gym_exercises_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966,
     "referenced_widgets": [
      "f408df12008d4f5fa0f8d442a964c020",
      "438daaf893f145948d1dcae12e1a3716",
      "d71a715871f74105b85f30d72ce2c549",
      "260d9e03a7dd4afd9a32a10d408fae76",
      "d8674856b30643d5be1b8503b53ba4be",
      "8412d650aca8458cb6e4011365aca1fb",
      "1c0e15331b374027ba1721eb40547eee",
      "0e5c9f735ded4ef08bc295650b64f7cb",
      "86b42f61f0f54b6e89a57f51a186bc06",
      "68825b31e5fb432588b37b77a7ea508d",
      "d169dc9a254d420e8f3fa7440e2eb17a",
      "99aafa32533748d8bda03e005a0fdc9d",
      "9ca52c7782c14a518c09a6cda11a1b4d",
      "1ec7b83a1441491ab21e660664a6114b",
      "47cda39ce07746e48951dafc14adf7ab",
      "54eada06f34f4cd29481fe3d16ca526b",
      "128e9aef38e44f0da58ebe0e063622ff",
      "a0c70931873d4683a715d2e5c2f8a7b1",
      "a4717cd8f1fe4efbb70c49c4e6663e17",
      "5a6b15d5f1e6400a866f6f0f95c24136",
      "f4564cfc5c8449e9a8160a66d35e7496",
      "113334b3b61c4cd29b81032f4e22ce5e",
      "a20eaa365eef4abbbba8e6c87334535d",
      "7dfc42213045431eb291d192259b8076",
      "0664fddb04b24dae932a318322e3a772",
      "e08b06e0910b4ca9b20fc80b5f70a0a0",
      "0fe0f53acce548a78f8b1b84edb66f00",
      "bdbe258c572b47aa8c3580d54e879c28",
      "71b8fd88ccf34752ac41a5e2f523424b",
      "3f7d6a5be140466c86c0e01ab2e99a10",
      "4d3213a2e2b842b493a0eca51739a7f1",
      "01220a5c899545a798d1c4f30678b377",
      "3d08ca866ec14ddaa844d306eee44242",
      "83bbd09e90c74eaa968d4b55a81a944e",
      "aa57456f376a424c8dd5aed3b49a3c85",
      "48b7a401128d439d834b2d05f7d75625",
      "f1f49d15c6f74f04954396607e2a11a3",
      "faaefc10b9e94602a05d2a0b3b76f2ed",
      "978a206134bc4c8e9f2d959885b48262",
      "a00b95be88704795a09757432bac160c",
      "fa012d78a8c74a77989c6ead8bd69803",
      "84244b0a3ec349519e311015c826be34",
      "e00ee72fc3d24cfcb63b5ac7a029fafa",
      "7276a3ab7cca48078b0d859753442bb6",
      "01158f040e354e44980ea783413f5893",
      "ca9451ab4801444bbb30da85b6efd3a6",
      "80cc8b8a024b4d38aafdf2ba57562bc7",
      "e658fbfc50934494a8d88f4a4bc3bf9c",
      "01a7539917b64b7b9230cfa924dacb63",
      "24f2ae9fe84247318b7af9d1e68c5ed6",
      "3809040586c34c059af278ad6e77e391",
      "061bf7a485064b9285061bf61eecfed0",
      "28358497b6694f17a8003907b4acab73",
      "a97d32dae7404b709aaf0f15ba7c1851",
      "6bc75c0b4c75494cabaa12d162cbdf09",
      "d1f4d21ee1064827a8023ad636e020c5",
      "4a3d685821eb45b19beb76203f1d816e",
      "ad79147a686045b3acb3dfa89094afd2",
      "c8182a1459754810a8215d10d74d9bc7",
      "132c136ea1e949959ff4fc1a8434286b",
      "5e185fb24c7f4022af1c1c9f77f744bb",
      "8d69a59383f0433481668a539cc26232",
      "a08d86d469274c229aefdbe7faef8370",
      "8607a500f1b94183ad28c39ff472742d",
      "d5f69f9700c740c59eb92495c2195c70",
      "22ac764f817a4bb39c1b398c538df845",
      "82313945900a4ade8e604335e8c084f8",
      "ed40c64c08bc42aead724c6171df41b1",
      "d70e5a2c878d4dfcb980565d3405cfbd",
      "02fbb337015b4fb28d8824155df69edb",
      "b7fd1685a2fb432190df352fb26bca35",
      "d3a1b2e2e77a4db19d4fb1179db8b71f",
      "25097e454ec04a6a897a251fcfa9a11f",
      "bd3787bf58c54c7e8cf852102d128462",
      "854306778243473ebace0ebc0f243308",
      "9ed919c7ddcf4a24ba2ee04bcdab599a",
      "cdff8d51fff543f2b6a098212b521e49",
      "a4f37b2c74014b928745f81cf5aab531",
      "e2b9910c948d4643a2fc591e040dd0fa",
      "5628ca5a44d44335ad2a4b09963224f8",
      "f2631d0082244c66bdfb33776e9a9089",
      "077e409869d749aca593de512e4cee93",
      "7a1d8caea81f453f81ec18e38c536e16",
      "bfae6528f4eb4b93adb5ee3f75f6ca78",
      "63071c2fcae04b6b95add476fe916b35",
      "26c586e967284191882f6c909436e501",
      "bd2d2be24adc418abe0c321006464da2",
      "71861d8c29d74ad9a5ff1109f1d3da8c"
     ]
    },
    "id": "zsFow91TImTX",
    "outputId": "a3b1afb7-b1d9-4a0e-8f21-1bd474f6e338"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f408df12008d4f5fa0f8d442a964c020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aafa32533748d8bda03e005a0fdc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20eaa365eef4abbbba8e6c87334535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bbd09e90c74eaa968d4b55a81a944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01158f040e354e44980ea783413f5893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f4d21ee1064827a8023ad636e020c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82313945900a4ade8e604335e8c084f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f37b2c74014b928745f81cf5aab531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maazaadrapurizx\u001b[0m (\u001b[33maazaadrapurizx-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251030_080548-o0okncw3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aazaadrapurizx-none/huggingface/runs/o0okncw3' target=\"_blank\">enchanted-newt-2</a></strong> to <a href='https://wandb.ai/aazaadrapurizx-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aazaadrapurizx-none/huggingface' target=\"_blank\">https://wandb.ai/aazaadrapurizx-none/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aazaadrapurizx-none/huggingface/runs/o0okncw3' target=\"_blank\">https://wandb.ai/aazaadrapurizx-none/huggingface/runs/o0okncw3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.584528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.699208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.410376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Step 1: Load and preprocess the datasets\n",
    "# Nutrition dataset\n",
    "nutrition_data = pd.read_csv(\"nutrition.csv\")\n",
    "nutrition_data = nutrition_data[[\"name\", \"calories\"]]\n",
    "\n",
    "# Gym exercises dataset\n",
    "gym_exercises_data = pd.read_csv(\"gym_members_exercise_tracking.csv\")\n",
    "gym_exercises_data = gym_exercises_data[[\"Workout_Type\", \"Calories_Burned\"]]\n",
    "\n",
    "# Create input-output pairs\n",
    "def create_pairs(calorie_ranges):\n",
    "    data = []\n",
    "    for calories in calorie_ranges:\n",
    "        # Select foods within calorie range\n",
    "        recommended_foods = nutrition_data[nutrition_data[\"calories\"] <= calories].head(5)[\"name\"].tolist()\n",
    "        food_recommendations = \", \".join(recommended_foods)\n",
    "\n",
    "        # Select exercises that burn at least the given calories\n",
    "        recommended_exercises = gym_exercises_data[gym_exercises_data[\"Calories_Burned\"] >= calories].head(5)[\"Workout_Type\"].tolist()\n",
    "        exercise_recommendations = \", \".join(recommended_exercises)\n",
    "\n",
    "        # Input prompt and expected output\n",
    "        prompt = f\"My daily calorie goal is {calories} calories. Suggest a diet and a workout plan.\"\n",
    "        response = (\n",
    "            f\"Diet: {food_recommendations}. \"\n",
    "            f\"Workout: {exercise_recommendations}. \"\n",
    "            f\"Tip: Combine a balanced diet with consistent exercise for best results.\"\n",
    "        )\n",
    "        data.append({\"input\": prompt, \"output\": response})\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Define calorie ranges for the chatbot\n",
    "calorie_ranges = [1500, 1800, 2000, 2200, 2500]\n",
    "\n",
    "# Generate dataset\n",
    "chatbot_data = create_pairs(calorie_ranges)\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(chatbot_data))\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Step 2: Load pretrained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Add padding token to tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token # using eos_token as pad_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset with padding and truncation\n",
    "def tokenize_data(example):\n",
    "    # using padding='max_length' and truncation=True to ensure consistent sequence lengths\n",
    "    return tokenizer(example[\"input\"], text_target=example[\"output\"], padding='max_length', truncation=True, max_length=50)\n",
    "    # Adjust max_length as needed based on the typical length of your input and output sequences\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Step 3: Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./trained_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Step 4: Save the trained model\n",
    "model.save_pretrained(\"./calorie_chatbot_model\")\n",
    "tokenizer.save_pretrained(\"./calorie_chatbot_model\")\n",
    "\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475,
     "referenced_widgets": [
      "fc67c4e37b2d457fa26c75da7bcc7fd9",
      "f5fb41682e644cc696a2b4aef5b21a33",
      "59e59e34a9b04d0b93e5656505501db2",
      "78c6955f44ca446aa3d30bb3f6f011bc",
      "1bf25e658c22416795ed71ece47cffbc",
      "ee011012f247477c969a23358a4fd297",
      "64ca3043190843f5aa2239aaf4c4ff7c",
      "a3ccb8da3c2b45b3a59fcdc4daa3d4dc",
      "34895be8f4ba46449bd37a6175762915",
      "6b6cb0e3be334a14bcd1f93dc0ef5da3",
      "451a54a92f6a4036b58a263f0c68c322"
     ]
    },
    "id": "kODtQsoqIryB",
    "outputId": "31376eb3-bf7e-41fb-c583-93759ddcd6a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc67c4e37b2d457fa26c75da7bcc7fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 03:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.936894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.349439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.166055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.116473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.083241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset with padding and truncation\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(\n",
    "        example[\"input\"],\n",
    "        text_target=example[\"output\"],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=100  # Adjust based on your input-output length\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Split dataset into training and evaluation sets\n",
    "train_size = int(0.8 * len(tokenized_dataset))\n",
    "eval_size = len(tokenized_dataset) - train_size\n",
    "train_dataset = tokenized_dataset.select(range(train_size))\n",
    "eval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tuned_model\",\n",
    "    eval_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    learning_rate=3e-5,  # Adjust for better fine-tuning\n",
    "    per_device_train_batch_size=4,  # Increase if your hardware allows\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,  # Increase epochs for more thorough fine-tuning\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",  # Suppress reporting to external tools\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "print(\"Fine-tuning complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kbItWuINJDrC",
    "outputId": "155aa76e-b1dc-41d0-8b27-5d9e2fc21304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udcaa Welcome to your AI Fitness Assistant!\n",
      "Type 'exit' anytime to quit.\n",
      "\n",
      "\ud83d\udc4b Hi! Let's personalize your fitness experience first.\n",
      "Chatbot: What is your gender? exit\n",
      "Chatbot: What is your height (in cm)? 1567\n",
      "Chatbot: What is your weight (in kg)? 600\n",
      "Chatbot: What is your age? 230\n",
      "\n",
      "Let's record your daily routine.\n",
      "Wake-up time (24h HH:MM): 12:10\n",
      "Sleep time (24h HH:MM): 12:19\n",
      "Breakfast time (or 'no'): 1:10\n",
      "Lunch time (or 'no'): 1:109\n",
      "Dinner time (or 'no'): 1:10\n",
      "Snack time (or 'no'): no\n",
      "Workout hours today (or 'no'): no\n",
      "Total steps taken today: 0\n",
      "\n",
      "\ud83d\udcca Daily routine saved successfully.\n",
      "\n",
      "You: analyze my routine\n",
      "Chatbot: Of course! I'd be happy to analyze your routine.\n",
      "\n",
      "However, to do that, you need to tell me what it is first. A good analysis depends on the details you provide and, most importantly, **what you want to achieve.**\n",
      "\n",
      "To give you the most helpful feedback, please describe your routine. The more detail, the better.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Share Your Routine & Goals**\n",
      "\n",
      "Please copy and paste the template below and fill it out. Don't worry about it being perfect; just a rough outline is a great start.\n",
      "\n",
      "**1. What are your main goals?** (e.g., be more productive, lose weight, reduce stress, have more free time, learn a new skill, sleep better?)\n",
      "*   Goal 1:\n",
      "*   Goal 2:\n",
      "*   Goal 3:\n",
      "\n",
      "**2. What are your biggest challenges or pain points right now?** (e.g., I always feel rushed, I procrastinate on big tasks, I'm too tired to exercise, I can't seem to wake up on time.)\n",
      "*   Challenge 1:\n",
      "*   Challenge 2:\n",
      "\n",
      "**3. What does a typical WEEKDAY look like for you?** (Be honest! Include the scrolling, the random breaks, etc.)\n",
      "*   **Morning (Wake-up - 12 PM):**\n",
      "*   **Afternoon (12 PM - 5 PM):**\n",
      "*   **Evening (5 PM - Sleep):**\n",
      "\n",
      "**4. What does a typical WEEKEND day look like?**\n",
      "*   **Morning:**\n",
      "*   **Afternoon:**\n",
      "*   **Evening:**\n",
      "\n",
      "---\n",
      "\n",
      "### **Example of a Good Submission:**\n",
      "\n",
      "Here's an example to show you the kind of detail that's helpful.\n",
      "\n",
      "> **1. My Goals:**\n",
      "> *   Goal 1: Lose 10 pounds.\n",
      "> *   Goal 2: Feel less stressed and burnt out from work.\n",
      "> *   Goal 3: Read at least one book per month.\n",
      ">\n",
      "> **2. My Challenges:**\n",
      "> *   Challenge 1: I hit snooze 3-4 times every morning and then feel rushed.\n",
      "> *   Challenge 2: I end up scrolling on my phone for an hour before bed, which I know is bad for my sleep.\n",
      ">\n",
      "> **3. My Typical Weekday:**\n",
      "> *   **Morning:**\n",
      ">     *   7:00 AM: Alarm goes off. Snooze until 7:45 AM.\n",
      ">     *   7:45 AM: Frantically get ready, grab a coffee, no breakfast.\n",
      ">     *   8:30 AM: Commute to work, listen to a podcast.\n",
      ">     *   9:00 AM - 12:00 PM: Work. Usually answer emails and attend meetings.\n",
      "> *   **Afternoon:**\n",
      ">     *   12:30 PM: Eat a quick sandwich at my desk while working.\n",
      ">     *   1:00 PM - 5:30 PM: More work. My energy crashes hard around 3 PM.\n",
      "> *   **Evening:**\n",
      ">     *   6:00 PM: Get home, feel exhausted.\n",
      ">     *   6:30 PM: Make dinner or get takeout.\n",
      ">     *   7:30 PM - 10:00 PM: Watch Netflix or YouTube to \"decompress.\"\n",
      ">     *   10:00 PM - 11:30 PM: Scroll on my phone in bed.\n",
      ">     *   11:30 PM: Try to sleep.\n",
      ">\n",
      "> **4. My Typical Weekend:**\n",
      "> *   Pretty unstructured. Wake up late, do chores, meet with friends, but I don't have a set schedule. I never get around to exercising or reading.\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: My Analysis**\n",
      "\n",
      "Once you provide your routine, I will analyze it by looking for:\n",
      "\n",
      "*   **Strengths:** What are you already doing well?\n",
      "*   **Alignment Gaps:** Are your daily actions actually helping you reach your stated goals?\n",
      "*   **Energy Drains:** Where are you losing momentum, focus, or motivation?\n",
      "*   **Opportunities:** Where can small, simple tweaks make a big impact?\n",
      "*   **Balance:** How is your time split between work, rest, play, and personal growth?\n",
      "\n",
      "I'm ready when you are. Lay it on me\n",
      "You: exit\n",
      "Chatbot: Stay healthy and see you soon! \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import google.generativeai as ai\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Local fine-tuned model\n",
    "MODEL_PATH = \"./fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Gemini API configuration\n",
    "API_KEY = \"apik-key\"  # Replace with your valid key\n",
    "ai.configure(api_key=API_KEY)\n",
    "gemini_model = ai.GenerativeModel(\"gemini-pro-latest\")\n",
    "chat = gemini_model.start_chat()\n",
    "\n",
    "\n",
    "gender = None\n",
    "height = None\n",
    "weight = None\n",
    "age = None\n",
    "\n",
    "def validate_and_format_time(user_time):\n",
    "    \"\"\"Validate and convert 24h time to 12h AM/PM format.\"\"\"\n",
    "    try:\n",
    "        time_obj = datetime.strptime(user_time, \"%H:%M\")\n",
    "        return time_obj.strftime(\"%I:%M %p\")\n",
    "    except ValueError:\n",
    "        return \"enter proper timings\"\n",
    "\n",
    "def calculate_calories_burned(weight, workout_hours, met_value=5):\n",
    "    \"\"\"Estimate calories burned based on weight and workout hours.\"\"\"\n",
    "    try:\n",
    "        return met_value * float(weight) * float(workout_hours)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def estimate_calories_consumed(breakfast_time, lunch_time, dinner_time, snack_time):\n",
    "    \"\"\"Estimate calories consumed based on meal pattern.\"\"\"\n",
    "    calories = 0\n",
    "    if breakfast_time.lower() != 'no': calories += 300\n",
    "    if lunch_time.lower() != 'no': calories += 600\n",
    "    if dinner_time.lower() != 'no': calories += 700\n",
    "    if snack_time.lower() != 'no': calories += 150\n",
    "    return calories\n",
    "\n",
    "# DATA COLLECTION\n",
    "def get_user_details():\n",
    "    \"\"\"Ask user for personal information once.\"\"\"\n",
    "    global gender, height, weight, age\n",
    "    print(\"\ud83d\udc4b Hi! Let's personalize your fitness experience first.\")\n",
    "    if gender is None:\n",
    "        gender = input(\"Chatbot: What is your gender? \")\n",
    "    if height is None:\n",
    "        height = input(\"Chatbot: What is your height (in cm)? \")\n",
    "    if weight is None:\n",
    "        weight = input(\"Chatbot: What is your weight (in kg)? \")\n",
    "    if age is None:\n",
    "        age = input(\"Chatbot: What is your age? \")\n",
    "\n",
    "def get_daily_routine():\n",
    "    \"\"\"Collect user's daily routine for logging and calorie tracking.\"\"\"\n",
    "    print(\"\\nLet's record your daily routine.\")\n",
    "\n",
    "    wake_up_time = validate_and_format_time(input(\"Wake-up time (24h HH:MM): \"))\n",
    "    sleep_time = validate_and_format_time(input(\"Sleep time (24h HH:MM): \"))\n",
    "\n",
    "    breakfast_time = input(\"Breakfast time (or 'no'): \")\n",
    "    breakfast_time = validate_and_format_time(breakfast_time) if breakfast_time.lower() != 'no' else 'no'\n",
    "\n",
    "    lunch_time = input(\"Lunch time (or 'no'): \")\n",
    "    lunch_time = validate_and_format_time(lunch_time) if lunch_time.lower() != 'no' else 'no'\n",
    "\n",
    "    dinner_time = input(\"Dinner time (or 'no'): \")\n",
    "    dinner_time = validate_and_format_time(dinner_time) if dinner_time.lower() != 'no' else 'no'\n",
    "\n",
    "    snack_time = input(\"Snack time (or 'no'): \")\n",
    "    snack_time = validate_and_format_time(snack_time) if snack_time.lower() != 'no' else 'no'\n",
    "\n",
    "    workout_hours = input(\"Workout hours today (or 'no'): \")\n",
    "    total_steps = input(\"Total steps taken today: \")\n",
    "\n",
    "    routine = {\n",
    "        \"Wake Up Time\": wake_up_time,\n",
    "        \"Sleep Time\": sleep_time,\n",
    "        \"Breakfast Time\": breakfast_time,\n",
    "        \"Lunch Time\": lunch_time,\n",
    "        \"Dinner Time\": dinner_time,\n",
    "        \"Snack Time\": snack_time,\n",
    "        \"Workout Hours\": workout_hours if workout_hours != '' else 'no',\n",
    "        \"Total Steps\": total_steps if total_steps != '' else 'no'\n",
    "    }\n",
    "    return routine\n",
    "\n",
    "# MODEL INTERACTIONS\n",
    "def query_gemini(prompt):\n",
    "    \"\"\"Send prompt to Gemini and return response text.\"\"\"\n",
    "    return chat.send_message(prompt).text\n",
    "\n",
    "def generate_diet_workout_response(calories):\n",
    "    \"\"\"Use local fine-tuned model to suggest diet/workout plan.\"\"\"\n",
    "    prompt = f\"My daily calorie goal is {calories} calories. Suggest a diet and workout plan.\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=200, temperature=0.7, top_p=0.9)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# MAIN FITNESS CHATBOT\n",
    "\n",
    "def fitness_chatbot():\n",
    "    \"\"\"Unified chatbot with calorie tracking, fitness tips, and Gemini chat.\"\"\"\n",
    "    print(\"\\n\ud83d\udcaa Welcome to your AI Fitness Assistant!\")\n",
    "    print(\"Type 'exit' anytime to quit.\\n\")\n",
    "\n",
    "    # Collect user info and daily routine first\n",
    "    get_user_details()\n",
    "    daily_routine = get_daily_routine()\n",
    "\n",
    "    # Add personal info\n",
    "    daily_routine[\"Gender\"] = gender\n",
    "    daily_routine[\"Height (cm)\"] = height\n",
    "    daily_routine[\"Weight (kg)\"] = weight\n",
    "    daily_routine[\"Age\"] = age\n",
    "\n",
    "    # Calculate calories\n",
    "    try:\n",
    "        workout_hours = float(daily_routine[\"Workout Hours\"]) if daily_routine[\"Workout Hours\"].lower() != 'no' else 0\n",
    "        calories_burned = calculate_calories_burned(weight, workout_hours)\n",
    "        daily_routine[\"Calories Burned\"] = calories_burned\n",
    "    except:\n",
    "        daily_routine[\"Calories Burned\"] = 0\n",
    "\n",
    "    calories_consumed = estimate_calories_consumed(\n",
    "        daily_routine[\"Breakfast Time\"], daily_routine[\"Lunch Time\"],\n",
    "        daily_routine[\"Dinner Time\"], daily_routine[\"Snack Time\"]\n",
    "    )\n",
    "    daily_routine[\"Calories Consumed\"] = calories_consumed\n",
    "\n",
    "    # Save to CSV\n",
    "    file_name = \"user_daily_routine.csv\"\n",
    "    df = pd.DataFrame([daily_routine])\n",
    "    df.to_csv(file_name, mode='a', header=not os.path.exists(file_name), index=False)\n",
    "    print(\"\\n\ud83d\udcca Daily routine saved successfully.\\n\")\n",
    "\n",
    "    # Start chat loop\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Stay healthy and see you soon! \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f\")\n",
    "            break\n",
    "\n",
    "        elif \"calorie goal\" in user_input.lower():\n",
    "            try:\n",
    "                calories = int(user_input.split(\"is\")[-1].strip().split()[0])\n",
    "                response = generate_diet_workout_response(calories)\n",
    "            except:\n",
    "                response = \"Please specify your calorie goal clearly (e.g., 'My daily calorie goal is 2000 calories.')\"\n",
    "\n",
    "        else:\n",
    "            response = query_gemini(user_input)\n",
    "\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fitness_chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj73t-hmLdPd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}