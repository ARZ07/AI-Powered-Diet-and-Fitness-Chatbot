{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b6agj0gIRtY",
    "outputId": "b8f3d011-0f57-4ae3-b169-0883d74e5a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.27.0)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.185.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers google-generativeai datasets pandas torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IFiUEDDIX6z",
    "outputId": "62fd1978-3ec0-4443-b82b-4fca9c107e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
      "-rw-r--r-- 1 root root 68 Oct 30 13:08 /root/.kaggle/kaggle.json\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "ref                                                            title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "-------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
      "ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset   Global Earthquake-Tsunami Risk Assessment Dataset       16151  2025-10-01 16:35:53.273000          16033        545  1.0              \n",
      "jockeroika/life-style-data                                     Life Style Data                                       3995645  2025-10-14 13:50:45.303000          18760        378  0.8235294        \n",
      "jaderz/hospital-beds-management                                Hospital Beds Management                                47583  2025-10-03 09:21:58.590000          13061        327  1.0              \n",
      "ayeshaimran123/social-media-and-mental-health-balance          Social Media and Mental Health Balance                   5941  2025-10-26 07:51:53.380000            871         28  1.0              \n",
      "ahmadrazakashif/bmw-worldwide-sales-records-20102024           BMW Worldwide Sales Records (2010‚Äì2024)                853348  2025-09-20 14:39:45.280000          16910        333  1.0              \n",
      "grandmaster07/student-exam-score-dataset-analysis              Student exam score dataset analysis                      2430  2025-09-26 07:44:12.677000           9175        205  1.0              \n",
      "ahmadrazakashif/netflix-streaming-data                         Netflix_Streaming_Data                                1400865  2025-10-09 17:53:56.590000           1639         32  1.0              \n",
      "mubeenshehzadi/customer-purchase-behaviour                     Customer Purchase Behaviour                             72157  2025-10-18 01:46:11.677000           1525         35  1.0              \n",
      "marixe/zara-sales-for-eda                                      Zara Sales for EDA üõçÔ∏è                                  954444  2025-10-26 12:40:24.927000           1057         22  1.0              \n",
      "alamshihab075/mental-health-dataset                            Mental Health Dataset                                 1109509  2025-10-23 11:29:29.797000           1163         33  1.0              \n",
      "afnansaifafnan/electric-car-performance-and-battery-dataset    Electric Car Performance and Battery Dataset            16631  2025-10-15 10:17:39.960000           1517         29  1.0              \n",
      "tan5577/heart-failure-dataset                                  Heart_Failure_Dataset                                    8762  2025-10-19 16:54:19.303000           1387         35  1.0              \n",
      "prince7489/mental-health-and-social-media-balance-dataset      Mental Health & Social Media Balance Dataset             5941  2025-10-15 15:56:35.387000           2462         62  0.9411765        \n",
      "ahmadrazakashif/shopping-behavior-dataset                      Shopping_Behavior_Dataset                               72157  2025-10-08 16:19:06.293000           2679         41  1.0              \n",
      "mohamedasak/imdb-top-250-movies                                IMDb Top 250 Movies                                     35115  2025-10-29 23:22:58.290000           1008         24  1.0              \n",
      "mohankrishnathalla/medical-insurance-cost-prediction           Medical Insurance Cost Prediction                     5897923  2025-10-10 15:35:01.663000           3035         68  1.0              \n",
      "ayeshaimran123/data-science-student-marks                      Data Science Student Marks                               5199  2025-10-09 08:22:41.593000           1542         55  1.0              \n",
      "anassarfraz13/student-success-factors-and-insights             Student Success: Factors & Insights                     96178  2025-09-24 07:58:55.117000           6305        106  1.0              \n",
      "ayeshaimran123/bmw-car-data-analysis                           BMW Car Data Analysis                                  112601  2025-10-17 05:34:49.407000           1247         35  1.0              \n",
      "mohankrishnathalla/mobile-reviews-sentiment-and-specification  Global Mobile Reviews Dataset (2025 Edition)          2211906  2025-10-22 16:01:13.550000           1284         29  1.0              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directly input your Kaggle API key and username\n",
    "kaggle_api_key = \"api-key\"\n",
    "kaggle_username = \"username\"\n",
    "\n",
    "# Set the environment variable for Kaggle API key\n",
    "os.environ['KAGGLE_JSON'] = kaggle_api_key\n",
    "\n",
    "# Install the Kaggle package\n",
    "!pip install kaggle\n",
    "\n",
    "# Create the directory for the Kaggle config if it doesn't exist\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "\n",
    "# Save the API key as a JSON file for authentication\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    f.write('{\"username\":\"' + kaggle_username + '\",\"key\":\"' + kaggle_api_key + '\"}')\n",
    "\n",
    "# Verify if the file is created\n",
    "!ls -alh /root/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLVp7dMsIeBZ",
    "outputId": "e2dd573b-b188-4535-b10b-2cb3b50f297d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/valakhorasani/gym-members-exercise-dataset\n",
      "License(s): apache-2.0\n",
      "Downloading gym-members-exercise-dataset.zip to /content\n",
      "  0% 0.00/21.6k [00:00<?, ?B/s]\n",
      "100% 21.6k/21.6k [00:00<00:00, 20.0MB/s]\n",
      "Archive:  gym-members-exercise-dataset.zip\n",
      "  inflating: gym_members_exercise_tracking.csv  \n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/trolukovich/nutritional-values-for-common-foods-and-products\n",
      "License(s): CC0-1.0\n",
      "Downloading nutritional-values-for-common-foods-and-products.zip to /content\n",
      "  0% 0.00/1.27M [00:00<?, ?B/s]\n",
      "100% 1.27M/1.27M [00:00<00:00, 196MB/s]\n",
      "Archive:  nutritional-values-for-common-foods-and-products.zip\n",
      "  inflating: nutrition.csv           \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d valakhorasani/gym-members-exercise-dataset\n",
    "!unzip gym-members-exercise-dataset\n",
    "!kaggle datasets download -d trolukovich/nutritional-values-for-common-foods-and-products\n",
    "!unzip nutritional-values-for-common-foods-and-products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2HITTDsIhEA",
    "outputId": "217df8fa-9111-445b-957f-c3e0c9b17aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             name serving_size  calories total_fat saturated_fat  \\\n",
      "0           0       Cornstarch        100 g       381      0.1g           NaN   \n",
      "1           1     Nuts, pecans        100 g       691       72g          6.2g   \n",
      "2           2    Eggplant, raw        100 g        25      0.2g           NaN   \n",
      "3           3   Teff, uncooked        100 g       367      2.4g          0.4g   \n",
      "4           4  Sherbet, orange        100 g       144        2g          1.2g   \n",
      "\n",
      "  cholesterol    sodium  choline     folate  ...      fat  \\\n",
      "0           0   9.00 mg   0.4 mg   0.00 mcg  ...   0.05 g   \n",
      "1           0   0.00 mg  40.5 mg  22.00 mcg  ...  71.97 g   \n",
      "2           0   2.00 mg   6.9 mg  22.00 mcg  ...   0.18 g   \n",
      "3           0  12.00 mg  13.1 mg          0  ...   2.38 g   \n",
      "4         1mg  46.00 mg   7.7 mg   4.00 mcg  ...   2.00 g   \n",
      "\n",
      "  saturated_fatty_acids monounsaturated_fatty_acids  \\\n",
      "0               0.009 g                     0.016 g   \n",
      "1               6.180 g                    40.801 g   \n",
      "2               0.034 g                     0.016 g   \n",
      "3               0.449 g                     0.589 g   \n",
      "4               1.160 g                     0.530 g   \n",
      "\n",
      "  polyunsaturated_fatty_acids fatty_acids_total_trans alcohol     ash  \\\n",
      "0                     0.025 g                 0.00 mg   0.0 g  0.09 g   \n",
      "1                    21.614 g                 0.00 mg   0.0 g  1.49 g   \n",
      "2                     0.076 g                 0.00 mg   0.0 g  0.66 g   \n",
      "3                     1.071 g                       0       0  2.37 g   \n",
      "4                     0.080 g                 1.00 mg   0.0 g  0.40 g   \n",
      "\n",
      "  caffeine theobromine    water  \n",
      "0  0.00 mg     0.00 mg   8.32 g  \n",
      "1  0.00 mg     0.00 mg   3.52 g  \n",
      "2  0.00 mg     0.00 mg  92.30 g  \n",
      "3        0           0   8.82 g  \n",
      "4  0.00 mg     0.00 mg  66.10 g  \n",
      "\n",
      "[5 rows x 77 columns]\n",
      "   Age  Gender  Weight (kg)  Height (m)  Max_BPM  Avg_BPM  Resting_BPM  \\\n",
      "0   56    Male         88.3        1.71      180      157           60   \n",
      "1   46  Female         74.9        1.53      179      151           66   \n",
      "2   32  Female         68.1        1.66      167      122           54   \n",
      "3   25    Male         53.2        1.70      190      164           56   \n",
      "4   38    Male         46.1        1.79      188      158           68   \n",
      "\n",
      "   Session_Duration (hours)  Calories_Burned Workout_Type  Fat_Percentage  \\\n",
      "0                      1.69           1313.0         Yoga            12.6   \n",
      "1                      1.30            883.0         HIIT            33.9   \n",
      "2                      1.11            677.0       Cardio            33.4   \n",
      "3                      0.59            532.0     Strength            28.8   \n",
      "4                      0.64            556.0     Strength            29.2   \n",
      "\n",
      "   Water_Intake (liters)  Workout_Frequency (days/week)  Experience_Level  \\\n",
      "0                    3.5                              4                 3   \n",
      "1                    2.1                              4                 2   \n",
      "2                    2.3                              4                 2   \n",
      "3                    2.1                              3                 1   \n",
      "4                    2.8                              3                 1   \n",
      "\n",
      "     BMI  \n",
      "0  30.20  \n",
      "1  32.00  \n",
      "2  24.71  \n",
      "3  18.41  \n",
      "4  14.39  \n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Log in to Hugging Face using your API key\n",
    "login(token=\"api-key\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the nutritional values dataset\n",
    "nutrition_data = pd.read_csv(\"nutrition.csv\")\n",
    "\n",
    "# Load the gym exercises dataset\n",
    "gym_exercises_data = pd.read_csv(\"gym_members_exercise_tracking.csv\")\n",
    "\n",
    "# Check the first few rows of both datasets\n",
    "print(nutrition_data.head())\n",
    "print(gym_exercises_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 586,
     "referenced_widgets": [
      "e69e85f7a2a649d08d6d3193059fc82f",
      "5a8649754ee04a0fa45615f3f909881d",
      "7d30b35e66514bbb87ac197e1c4d5dbe",
      "52e513588ed74f2a8df803efe554b815",
      "7a2360fd688c464aa141c8f552797891",
      "1e723c11d3d54b5c98c2d05fafac9e66",
      "7c9592dfe6f44dc88cd76a134e3b886b",
      "684d8e4dc72646e5b1e16792b47b35dd",
      "daad6451de9142ce8f104bc3953dabc4",
      "ee1c1d5b674549aa92a8b4c79e43f20e",
      "da193946154c4c11bc940a90bd787847"
     ]
    },
    "id": "zsFow91TImTX",
    "outputId": "9659608d-6357-4f1c-bf3a-f81de86e5298"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69e85f7a2a649d08d6d3193059fc82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maazaadrapurizx\u001b[0m (\u001b[33maazaadrapurizx-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251030_130919-4alpxymi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aazaadrapurizx-none/huggingface/runs/4alpxymi' target=\"_blank\">mystical-spider-3</a></strong> to <a href='https://wandb.ai/aazaadrapurizx-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aazaadrapurizx-none/huggingface' target=\"_blank\">https://wandb.ai/aazaadrapurizx-none/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aazaadrapurizx-none/huggingface/runs/4alpxymi' target=\"_blank\">https://wandb.ai/aazaadrapurizx-none/huggingface/runs/4alpxymi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.584528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.699208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.410376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "#wandb.ai api key = 4500fe60d22966f978a182ca4d68e77904a57a0d\n",
    "# Step 1: Load and preprocess the datasets\n",
    "# Nutrition dataset\n",
    "nutrition_data = pd.read_csv(\"nutrition.csv\")\n",
    "nutrition_data = nutrition_data[[\"name\", \"calories\"]]\n",
    "\n",
    "# Gym exercises dataset\n",
    "gym_exercises_data = pd.read_csv(\"gym_members_exercise_tracking.csv\")\n",
    "gym_exercises_data = gym_exercises_data[[\"Workout_Type\", \"Calories_Burned\"]]\n",
    "\n",
    "# Create input-output pairs\n",
    "def create_pairs(calorie_ranges):\n",
    "    data = []\n",
    "    for calories in calorie_ranges:\n",
    "        # Select foods within calorie range\n",
    "        recommended_foods = nutrition_data[nutrition_data[\"calories\"] <= calories].head(5)[\"name\"].tolist()\n",
    "        food_recommendations = \", \".join(recommended_foods)\n",
    "\n",
    "        # Select exercises that burn at least the given calories\n",
    "        recommended_exercises = gym_exercises_data[gym_exercises_data[\"Calories_Burned\"] >= calories].head(5)[\"Workout_Type\"].tolist()\n",
    "        exercise_recommendations = \", \".join(recommended_exercises)\n",
    "\n",
    "        # Input prompt and expected output\n",
    "        prompt = f\"My daily calorie goal is {calories} calories. Suggest a diet and a workout plan.\"\n",
    "        response = (\n",
    "            f\"Diet: {food_recommendations}. \"\n",
    "            f\"Workout: {exercise_recommendations}. \"\n",
    "            f\"Tip: Combine a balanced diet with consistent exercise for best results.\"\n",
    "        )\n",
    "        data.append({\"input\": prompt, \"output\": response})\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Define calorie ranges for the chatbot\n",
    "calorie_ranges = [1500, 1800, 2000, 2200, 2500]\n",
    "\n",
    "# Generate dataset\n",
    "chatbot_data = create_pairs(calorie_ranges)\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(chatbot_data))\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Step 2: Load pretrained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Add padding token to tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token # using eos_token as pad_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset with padding and truncation\n",
    "def tokenize_data(example):\n",
    "    # using padding='max_length' and truncation=True to ensure consistent sequence lengths\n",
    "    return tokenizer(example[\"input\"], text_target=example[\"output\"], padding='max_length', truncation=True, max_length=50)\n",
    "    # Adjust max_length as needed based on the typical length of your input and output sequences\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Step 3: Fine-tune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./trained_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Step 4: Save the trained model\n",
    "model.save_pretrained(\"./calorie_chatbot_model\")\n",
    "tokenizer.save_pretrained(\"./calorie_chatbot_model\")\n",
    "\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475,
     "referenced_widgets": [
      "4fa91d32ac4048d7814624adc960fb20",
      "6f37f931583d4b68b1b5465fee6f213f",
      "fbbe7f325d01468fad647e9b866d2b34",
      "fb534ecdd14e413d9144643e6184f516",
      "96311e9eb5a9495191d58d674d16d7b9",
      "2993186f0c8d4086986e4d00f0dcd2dc",
      "736724bd3cd44d68a300803b6c6eaf65",
      "bde798b11ff14a8799d689426e77951d",
      "9eeac6c3c17e460ba18dd166c6ce73df",
      "c92e40f4bd8d48babe0b2e48a5618e2a",
      "1f8fc69b47304201899bdeaf653bd721"
     ]
    },
    "id": "kODtQsoqIryB",
    "outputId": "947d35e1-03d2-4ddd-acff-ad082c7be371"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa91d32ac4048d7814624adc960fb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 02:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.936894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.349439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.166055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.116473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.083241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset with padding and truncation\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(\n",
    "        example[\"input\"],\n",
    "        text_target=example[\"output\"],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=100  # Adjust based on your input-output length\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Split dataset into training and evaluation sets\n",
    "train_size = int(0.8 * len(tokenized_dataset))\n",
    "eval_size = len(tokenized_dataset) - train_size\n",
    "train_dataset = tokenized_dataset.select(range(train_size))\n",
    "eval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tuned_model\",\n",
    "    eval_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    learning_rate=3e-5,  # Adjust for better fine-tuning\n",
    "    per_device_train_batch_size=4,  # Increase if your hardware allows\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,  # Increase epochs for more thorough fine-tuning\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",  # Suppress reporting to external tools\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "print(\"Fine-tuning complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Sa88GmDfRqXf",
    "outputId": "c0058334-b8e9-49c1-8f5d-32fc21f99644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí™ Welcome to your AI Fitness Assistant!\n",
      "Type 'exit' anytime to quit.\n",
      "\n",
      "üëã Hi! Let's personalize your fitness experience first.\n",
      "Chatbot: What is your gender? male\n",
      "Chatbot: What is your height? 157\n",
      "Chatbot: What is your weight? 62\n",
      "Chatbot: What is your age? 22\n",
      "You: analyse my routine and provide a workout routine for me\n",
      "\n",
      "Let's record your daily routine.\n",
      "Wake-up time (24h HH:MM): 7:30\n",
      "Sleep time (24h HH:MM): 10:20\n",
      "Breakfast time (or 'no'): 8:15\n",
      "Lunch time (or 'no'): 1:15\n",
      "Dinner time (or 'no'): 8:20\n",
      "Snack time (or 'no'): 4:30\n",
      "Workout hours today (or 'no'): no\n",
      "Total steps taken today: 46\n",
      "Chatbot: Your routine has been saved. ‚úÖ\n",
      "Chatbot: üìä **Your Daily Analysis**\n",
      "- Calories Consumed: 1750 kcal\n",
      "- Calories Burned: 0.0 kcal\n",
      "- Net Calories: 1750.0 kcal\n",
      "- Steps Taken: 46\n",
      "- Workout Hours: no\n",
      "\n",
      "You: provide a workout plan for me\n",
      "Chatbot: Of course! To give you the best possible workout plan, I need a little more information about you. A great workout plan is personal.\n",
      "\n",
      "**Please tell me:**\n",
      "\n",
      "1.  **What is your primary goal?** (e.g., lose weight, build muscle, improve general fitness, increase strength, improve endurance)\n",
      "2.  **What is your fitness level?** (e.g., complete beginner, some experience, very experienced)\n",
      "3.  **How many days per week can you work out?** And for how long each session? (e.g., 3 days for 45-60 mins)\n",
      "4.  **What equipment do you have access to?** (e.g., full gym, just dumbbells, resistance bands, only your bodyweight)\n",
      "5.  **Are there any injuries or limitations I should know about?**\n",
      "\n",
      "---\n",
      "\n",
      "### **General Purpose Workout Plan (For Beginners)**\n",
      "\n",
      "Since I don't have your specific details yet, here is a well-rounded, effective plan designed for a **beginner** looking for **general fitness and strength**.\n",
      "\n",
      "*   **Goal:** Build a foundation of strength, improve body composition, and increase overall fitness.\n",
      "*   **Frequency:** 3 days per week (e.g., Monday, Wednesday, Friday) to allow for recovery.\n",
      "*   **Equipment:** Assumes access to a basic gym with dumbbells and machines. (Bodyweight-only alternatives are listed below).\n",
      "*   **Duration:** 45-60 minutes per session.\n",
      "\n",
      "---\n",
      "\n",
      "### **Guiding Principles**\n",
      "\n",
      "*   **Warm-Up (5-10 minutes):** Never skip this. It prepares your body for exercise and prevents injury.\n",
      "*   **Focus on Form:** Perfect form is more important than lifting heavy weight. Watch videos of the exercises if you're unsure. Start with light weights or just your bodyweight.\n",
      "*   **Progressive Overload:** To keep making progress, you need to challenge your muscles. Each week, try to do one more rep, or increase the weight slightly.\n",
      "*   **Cool-Down (5 minutes):** Helps with recovery and flexibility.\n",
      "*   **Listen to Your Body:** Muscle soreness is normal. Sharp pain is not. Rest when you need to.\n",
      "\n",
      "---\n",
      "\n",
      "### **The Weekly Schedule: 3-Day Full Body Split**\n",
      "\n",
      "This approach works all your major muscle groups three times a week, which is great for building a solid base.\n",
      "\n",
      "#### **Workout A**\n",
      "\n",
      "| Exercise            | Sets | Reps    | Notes & Focus                                                 |\n",
      "| ------------------- | ---- | ------- | ------------------------------------------------------------- |\n",
      "| **Warm-Up**         | -    | 5-10 min| Light cardio (jogging, cycling), dynamic stretches (arm circles, leg swings). |\n",
      "| **1. Goblet Squats**  | 3    | 8-12    | Keep your chest up and back straight. Go as deep as you can comfortably. |\n",
      "| **2. Push-Ups**       | 3    | As many as you can (AMRAP) | Knees on the floor is a great option. Keep your core tight. |\n",
      "| **3. Dumbbell Rows**  | 3    | 8-12 per arm | Rest one knee on a bench. Pull the dumbbell towards your hip, squeezing your back. |\n",
      "| **4. Overhead Press (Dumbbell)** | 3    | 8-12    | Sit on a bench with back support. Press dumbbells straight up overhead. |\n",
      "| **5. Plank**          | 3    | 30-60 sec hold | Keep your body in a straight line from head to heels. Don't let your hips sag. |\n",
      "| **Cardio (Optional)** | -    | 20-30 min| Moderate intensity (brisk walk, elliptical, bike). |\n",
      "| **Cool-Down**       | -    | 5-10 min| Static stretching (hold each stretch for 20-30 seconds). |\n",
      "\n",
      "---\n",
      "\n",
      "#### **Workout B**\n",
      "\n",
      "| Exercise                    | Sets | Reps    | Notes & Focus                                                 |\n",
      "| --------------------------- | ---- | ------- | ------------------------------------------------------------- |\n",
      "| **Warm-Up**                 | -    | 5-10 min| Light cardio (jogging, cycling), dynamic stretches.             |\n",
      "| **1. Romanian Deadlifts (Dumbbell)** | 3    | 10-15   | Keep a slight bend in your knees. Hinge at your hips, keeping your back flat. Feel the stretch in your hamstrings. |\n",
      "| **2. Dumbbell Bench Press**   | 3    | 8-12    | Lie on a flat bench. Lower the dumbbells to your chest and press back up. |\n",
      "| **3. Lat Pulldowns** (Machine) | 3    | 8-12    | Grab the bar wide. Pull it down to your upper chest, squeezing your shoulder blades together. |\n",
      "| **4. Lunges**                 | 3    | 10-12 per leg | Step forward and lower your hips until both knees are bent at a 90-degree angle. |\n",
      "| **5. Glute Bridges**          | 3    | 15-20   | Lie on your back, knees bent. Squeeze your glutes to lift your hips off the floor. |\n",
      "| **Cardio (Optional)**         | -    | 20-30 min| Moderate intensity (brisk walk, elliptical, bike).             |\n",
      "| **Cool-Down**               | -    | 5-10 min| Static stretching (hold each stretch for 20-30 seconds). |\n",
      "\n",
      "---\n",
      "\n",
      "### **How to Structure Your Week**\n",
      "\n",
      "*   **Week 1:** A, B, A\n",
      "*   **Week 2:** B, A, B\n",
      "*   **Week 3:** A, B, A\n",
      "*   And so on...\n",
      "\n",
      "**Example Week:**\n",
      "*   Monday: Workout A\n",
      "*   Tuesday: Rest or light activity (like a walk)\n",
      "*   Wednesday: Workout B\n",
      "*   Thursday: Rest or light activity\n",
      "*   Friday: Workout A\n",
      "*   Saturday/Sunday: Rest or light activity\n",
      "\n",
      "---\n",
      "\n",
      "### **Customization & Alternatives**\n",
      "\n",
      "#### **If Your Goal is WEIGHT LOSS:**\n",
      "*   **Prioritize Cardio:** Aim to do the optional 20-30 minutes of cardio after every strength session. Consider adding a 4th day of just cardio.\n",
      "*   **Increase Intensity:** Shorten rest periods between sets (to 45-60 seconds) to keep your heart rate up.\n",
      "*   **Diet is Key:** A workout plan is only half the battle. Focus on a healthy diet with a slight calorie deficit.\n",
      "\n",
      "#### **If Your Goal is MUSCLE GAIN:**\n",
      "*   **Focus on Progressive Overload:** You MUST get stronger over time. Track your lifts and aim to increase the weight or reps each week.\n",
      "*   **Eat Enough Protein:** Aim for adequate protein intake to help your muscles repair and grow.\n",
      "*   **Rest:** Your muscles grow when you're resting, not when you're working out. Make sure you're getting enough sleep.\n",
      "\n",
      "#### **If You ONLY HAVE YOUR BODYWEIGHT:**\n",
      "*   **Workout A:**\n",
      "    *   Goblet Squat -> **Bodyweight Squats** (3 sets of 15-20)\n",
      "    *   Push-Ups -> **Push-Ups** (on knees or toes)\n",
      "    *   Dumbbell Rows -> **Inverted Rows** (if you have a sturdy table) or **Supermans** (3 sets of 15-20)\n",
      "    *   Overhead Press -> **Pike Push-Ups** (3 sets, AMRAP)\n",
      "    *   Plank -> **Plank**\n",
      "*   **Workout B:**\n",
      "    *   Romanian Deadlifts -> **Glute Bridges** (Single leg if you can)\n",
      "    *   Dumbbell Bench Press -> **Decline Push-Ups** (feet on a chair)\n",
      "    *   Lat Pulldowns -> **Towel Rows** (loop a towel around a doorknob/pole) or **Supermans**\n",
      "    *   Lunges -> **Bodyweight Lunges**\n",
      "    *   Glute Bridges -> **Glute Bridges**\n",
      "\n",
      "**Once you provide your specific details, I can create a much more personalized and effective plan for you!**\n",
      "You: bye\n",
      "Chatbot: Stay healthy and see you soon! üèãÔ∏è‚Äç‚ôÇÔ∏è\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import google.generativeai as ai\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "MODEL_PATH = \"./fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Gemini API\n",
    "API_KEY = \"api-key\"  # Replace with your valid key\n",
    "ai.configure(api_key=API_KEY)\n",
    "gemini_model = ai.GenerativeModel(\"gemini-pro-latest\")\n",
    "chat = gemini_model.start_chat()\n",
    "\n",
    "user_info = {\"gender\": None, \"height\": None, \"weight\": None, \"age\": None}\n",
    "daily_routine = {}\n",
    "\n",
    "\n",
    "def validate_and_format_time(user_time):\n",
    "    \"\"\"Validate and convert 24h time to 12h AM/PM format.\"\"\"\n",
    "    try:\n",
    "        time_obj = datetime.strptime(user_time, \"%H:%M\")\n",
    "        return time_obj.strftime(\"%I:%M %p\")\n",
    "    except ValueError:\n",
    "        return \"enter proper timings\"\n",
    "\n",
    "def calculate_calories_burned(weight, workout_hours, met_value=5):\n",
    "    \"\"\"Estimate calories burned based on weight and workout hours.\"\"\"\n",
    "    try:\n",
    "        return met_value * float(weight) * float(workout_hours)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def estimate_calories_consumed(breakfast_time, lunch_time, dinner_time, snack_time):\n",
    "    \"\"\"Estimate calories consumed based on meal pattern.\"\"\"\n",
    "    calories = 0\n",
    "    if breakfast_time.lower() != 'no': calories += 300\n",
    "    if lunch_time.lower() != 'no': calories += 600\n",
    "    if dinner_time.lower() != 'no': calories += 700\n",
    "    if snack_time.lower() != 'no': calories += 150\n",
    "    return calories\n",
    "\n",
    "\n",
    "def get_user_details():\n",
    "    \"\"\"Ask user for personal information once.\"\"\"\n",
    "    print(\"üëã Hi! Let's personalize your fitness experience first.\")\n",
    "    for key in user_info:\n",
    "        if user_info[key] is None:\n",
    "            user_info[key] = input(f\"Chatbot: What is your {key}? \")\n",
    "\n",
    "def get_daily_routine():\n",
    "    \"\"\"Collect user's daily routine.\"\"\"\n",
    "    print(\"\\nLet's record your daily routine.\")\n",
    "    routine = {}\n",
    "\n",
    "    wake_up_time = validate_and_format_time(input(\"Wake-up time (24h HH:MM): \"))\n",
    "    sleep_time = validate_and_format_time(input(\"Sleep time (24h HH:MM): \"))\n",
    "\n",
    "    breakfast_time = input(\"Breakfast time (or 'no'): \")\n",
    "    breakfast_time = validate_and_format_time(breakfast_time) if breakfast_time.lower() != 'no' else 'no'\n",
    "\n",
    "    lunch_time = input(\"Lunch time (or 'no'): \")\n",
    "    lunch_time = validate_and_format_time(lunch_time) if lunch_time.lower() != 'no' else 'no'\n",
    "\n",
    "    dinner_time = input(\"Dinner time (or 'no'): \")\n",
    "    dinner_time = validate_and_format_time(dinner_time) if dinner_time.lower() != 'no' else 'no'\n",
    "\n",
    "    snack_time = input(\"Snack time (or 'no'): \")\n",
    "    snack_time = validate_and_format_time(snack_time) if snack_time.lower() != 'no' else 'no'\n",
    "\n",
    "    workout_hours = input(\"Workout hours today (or 'no'): \")\n",
    "    total_steps = input(\"Total steps taken today: \")\n",
    "\n",
    "    routine.update({\n",
    "        \"Wake Up Time\": wake_up_time,\n",
    "        \"Sleep Time\": sleep_time,\n",
    "        \"Breakfast Time\": breakfast_time,\n",
    "        \"Lunch Time\": lunch_time,\n",
    "        \"Dinner Time\": dinner_time,\n",
    "        \"Snack Time\": snack_time,\n",
    "        \"Workout Hours\": workout_hours if workout_hours != '' else 'no',\n",
    "        \"Total Steps\": total_steps if total_steps != '' else 'no'\n",
    "    })\n",
    "\n",
    "    # Add personal info\n",
    "    routine.update({\n",
    "        \"Gender\": user_info[\"gender\"],\n",
    "        \"Height (cm)\": user_info[\"height\"],\n",
    "        \"Weight (kg)\": user_info[\"weight\"],\n",
    "        \"Age\": user_info[\"age\"]\n",
    "    })\n",
    "\n",
    "    return routine\n",
    "\n",
    "def query_gemini(prompt):\n",
    "    \"\"\"Send prompt to Gemini and return response text.\"\"\"\n",
    "    return chat.send_message(prompt).text\n",
    "\n",
    "def generate_diet_workout_response(calories):\n",
    "    \"\"\"Use local fine-tuned model to suggest diet/workout plan.\"\"\"\n",
    "    prompt = f\"My daily calorie goal is {calories} calories. Suggest a diet and workout plan.\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=200, temperature=0.7, top_p=0.9)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def analyze_routine(routine):\n",
    "    \"\"\"Analyze routine and provide calorie summary.\"\"\"\n",
    "    try:\n",
    "        workout_hours = float(routine[\"Workout Hours\"]) if routine[\"Workout Hours\"].lower() != 'no' else 0\n",
    "        calories_burned = calculate_calories_burned(routine[\"Weight (kg)\"], workout_hours)\n",
    "        routine[\"Calories Burned\"] = calories_burned\n",
    "    except:\n",
    "        routine[\"Calories Burned\"] = 0\n",
    "\n",
    "    calories_consumed = estimate_calories_consumed(\n",
    "        routine[\"Breakfast Time\"], routine[\"Lunch Time\"],\n",
    "        routine[\"Dinner Time\"], routine[\"Snack Time\"]\n",
    "    )\n",
    "    routine[\"Calories Consumed\"] = calories_consumed\n",
    "\n",
    "    # Save to CSV\n",
    "    file_name = \"user_daily_routine.csv\"\n",
    "    df = pd.DataFrame([routine])\n",
    "    df.to_csv(file_name, mode='a', header=not os.path.exists(file_name), index=False)\n",
    "\n",
    "    # Generate a readable summary\n",
    "    summary = (\n",
    "        f\"üìä **Your Daily Analysis**\\n\"\n",
    "        f\"- Calories Consumed: {routine['Calories Consumed']} kcal\\n\"\n",
    "        f\"- Calories Burned: {routine['Calories Burned']} kcal\\n\"\n",
    "        f\"- Net Calories: {routine['Calories Consumed'] - routine['Calories Burned']} kcal\\n\"\n",
    "        f\"- Steps Taken: {routine['Total Steps']}\\n\"\n",
    "        f\"- Workout Hours: {routine['Workout Hours']}\\n\"\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "def fitness_chatbot():\n",
    "    print(\"\\nüí™ Welcome to your AI Fitness Assistant!\")\n",
    "    print(\"Type 'exit' anytime to quit.\\n\")\n",
    "\n",
    "    get_user_details()\n",
    "\n",
    "    global daily_routine\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip().lower()\n",
    "\n",
    "        if user_input in [\"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Stay healthy and see you soon! üèãÔ∏è‚Äç‚ôÇÔ∏è\")\n",
    "            break\n",
    "\n",
    "        elif \"routine\" in user_input:\n",
    "            if not daily_routine:\n",
    "                daily_routine = get_daily_routine()\n",
    "                print(\"Chatbot: Your routine has been saved. ‚úÖ\")\n",
    "                print(\"Chatbot:\", analyze_routine(daily_routine))\n",
    "            else:\n",
    "                # Instead of just saying \"I have it\", actually show the analysis\n",
    "                print(\"Chatbot: Here's your current routine summary üëá\")\n",
    "                print(analyze_routine(daily_routine))\n",
    "\n",
    "        elif \"analyze\" in user_input or \"calorie\" in user_input:\n",
    "            if not daily_routine:\n",
    "                print(\"Chatbot: I don't have your routine yet. Let's record it first.\")\n",
    "                daily_routine = get_daily_routine()\n",
    "            print(\"Chatbot:\", analyze_routine(daily_routine))\n",
    "\n",
    "        elif \"calorie goal\" in user_input:\n",
    "            try:\n",
    "                calories = int(user_input.split(\"is\")[-1].strip().split()[0])\n",
    "                response = generate_diet_workout_response(calories)\n",
    "            except:\n",
    "                response = \"Please specify your calorie goal clearly (e.g., 'My daily calorie goal is 2000 calories.')\"\n",
    "            print(\"Chatbot:\", response)\n",
    "\n",
    "        else:\n",
    "            response = query_gemini(user_input)\n",
    "            print(\"Chatbot:\", response)\n",
    "\n",
    "# ----------------------------\n",
    "# RUN\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    fitness_chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU0gAWULS6rI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the notebook\n",
    "with open(\"/content/AI_powered_diet_and_fitness_chatbot.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Remove 'widgets' metadata if it exists\n",
    "if \"widgets\" in nb.get(\"metadata\", {}):\n",
    "    del nb[\"metadata\"][\"widgets\"]\n",
    "\n",
    "# Save the cleaned notebook\n",
    "with open(\"your_notebook_clean.ipynb\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nb, f, indent=1)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
